{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a1918d-3cb3-4f2e-bc69-4e3653834268",
   "metadata": {},
   "source": [
    "**Tutorial 1. Data Aggregation: Summarising Data with Mean, Median, Mode, Standard Deviation,Variance, Quantiles, and Percentiles**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291c6c7-f828-4149-bd9c-adcb85cfca49",
   "metadata": {},
   "source": [
    "***1.1. Mean, Median, Mode, Standard Deviation, Max, Min in Pandas DataFrame***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8975d3b0-1e9b-49a7-8c47-4990368eceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Read the json file from the direcotory\n",
    "diabities_df = pd.read_csv(\"/data/chapter1/diabetes.csv\")\n",
    "\n",
    "print(f'\\n Mean \\n \\n {diabities_df.mean()}')\n",
    "\n",
    "print(f'\\n Median \\n \\n {diabities_df.median()}')\n",
    "\n",
    "print(f'\\n Mode \\n \\n {diabities_df.mode()}')\n",
    "\n",
    "print(f'\\n Varience \\n \\n {diabities_df.var()}')\n",
    "\n",
    "print(f'\\n Maximum \\n \\n {diabities_df.max()}')\n",
    "\n",
    "print(f'\\n Minimum \\n \\n {diabities_df.min()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3949f3e-9ae1-459b-b179-43e138f5aba0",
   "metadata": {},
   "source": [
    "***1.2. Mean, Median, Mode, Standard Deviation, Max, Min in Numpy Array***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf325fb2-97dd-4ac3-8899-aaf44fe6f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statistics as st\n",
    "\n",
    "# Create a numpy array\n",
    "data = np.array([12, 15, 20, 25, 30, 30, 35, 40, 45, 50])\n",
    "\n",
    "# Mean\n",
    "mean = np.mean(data)\n",
    "\n",
    "# Median\n",
    "median = np.median(data)\n",
    "\n",
    "# Mode\n",
    "mode_result = st.mode(data)\n",
    "mode_result\n",
    "\n",
    "# Standard Deviation\n",
    "std_dev = np.std(data)\n",
    "\n",
    "# Maximum\n",
    "maximum = np.max(data)\n",
    "\n",
    "# Minimum\n",
    "minimum = np.min(data)\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Mode:\", mode)\n",
    "print(\"Standard Deviation:\", std_dev)\n",
    "print(\"Maximum:\", maximum)\n",
    "print(\"Minimum:\", minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb99ae17-92d7-4a17-8fcb-46738c188a02",
   "metadata": {},
   "source": [
    "***1.3. Variance, Quantiles, and Percentiles are computed using `var()` and `quantiles` also the `describe()` shows it***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d22b3-31ba-47d3-9f38-16c72a30df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Read the json file from the direcotory\n",
    "diabities_df = pd.read_csv(\"/workspaces/ImplementingStatisticsWithPython/data/chapter1/diabetes.csv\")\n",
    "\n",
    "# Variance\n",
    "variance = diabities_df.var()\n",
    "\n",
    "# Quantiles (25th, 50th, and 75th percentiles)\n",
    "quantiles = diabities_df.quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "# Percentiles (90th and 95th percentiles)\n",
    "percentiles = diabities_df.quantile([0.9, 0.95])\n",
    "\n",
    "display(\"Variance:\", variance)\n",
    "display(\"Quantiles:\", quantiles)\n",
    "display(\"Percentiles:\", percentiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8edb103-9507-4216-8807-647525e004d7",
   "metadata": {},
   "source": [
    "**Tutorial 2. Data Normalisation, Standardization, Transformation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db544176-d722-41b1-a8d2-e12e4c145b3f",
   "metadata": {},
   "source": [
    "***2.1. Data Normalization on a Numpy array***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25f1d7-d707-4092-a8a3-d3fdfa564617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Structured data (2D array)\n",
    "structured_data = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "scaler = MinMaxScaler()\n",
    "normalized_structured = scaler.fit_transform(structured_data)\n",
    "\n",
    "print(\"Normalized Structured Data:\")\n",
    "print(normalized_structured)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad4bd8-f615-40ba-bdda-2a37ac57b0fc",
   "metadata": {},
   "source": [
    "***2.2. Data Normalization on Pandas DataFrame***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51678968-d6ad-44a9-9a56-5f950770011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Read the json file from the direcotory\n",
    "diabities_df = pd.read_csv(\"/workspaces/ImplementingStatisticsWithPython/data/chapter1/diabetes.csv\")\n",
    "\n",
    "# Specify columns to normalize\n",
    "columns_to_normalize = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Outcome']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "diabities_df[columns_to_normalize] = scaler.fit_transform(diabities_df[columns_to_normalize])\n",
    "\n",
    "print(\"Normalized Structured Data:\")\n",
    "diabities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c3f74-2ac4-4e09-a575-6126f2684fdb",
   "metadata": {},
   "source": [
    "In unstructuctered data like text normalization may involve natural language processing like convert lowercase , removing punctuation, \n",
    "handling special character like whitespaces and many more.\n",
    "<br>\n",
    "As shows in ***Tutorial 2.3.***\n",
    "In image or audio it may involve rescaling pixel values, extracting features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f6b06f-7de4-4a63-87a0-3b65425db18d",
   "metadata": {},
   "source": [
    "***Tutorial 2.3. Convert lowercase , removing punctuation, handling special character like whitespaces in unstructured text data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f2e740-b242-49e8-a8e1-440158ece00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Sample unstructured text data\n",
    "unstructured_text = \"This is an a text for book Implementing Stat with Python, with! various punctuation marks...\"\n",
    "\n",
    "normalized_text = normalize_text(unstructured_text)\n",
    "print(\"Original Text:\", unstructured_text)\n",
    "print(\"Normalized Text:\", normalized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c680e16a-fb45-4431-91d1-3519130a4032",
   "metadata": {},
   "source": [
    "**Tutorial 3. Data Binning, Grouping and Encoding**\n",
    "<br>\n",
    "Data binning summerizes, preprocess data. It is important to handle noisy data, statical inference, detecting pattern, performing analysis.\n",
    "<br>\n",
    "Group set of contineous data points into discreate interval or bins. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51195012-fc8c-4707-83a6-2545159264e5",
   "metadata": {},
   "source": [
    "***3.1. Data Binning in pandas DataFrame***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8201243-9df0-4b3a-8e34-e3d30315ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Read the json file from the direcotory\n",
    "diabities_df = pd.read_csv(\"/workspaces/ImplementingStatisticsWithPython/data/chapter1/diabetes.csv\")\n",
    "\n",
    "# Define the bin intervals\n",
    "bin_edges = [0, 30, 60, 100]\n",
    "\n",
    "# Use cut to create a new column with bin labels\n",
    "diabities_df['Age_Group'] = pd.cut(diabities_df['Age'], bins=bin_edges, labels=['<30', '30-60', '60-100'])\n",
    "\n",
    "# Count the number of people in each age group\n",
    "age_group_counts = diabities_df['Age_Group'].value_counts().sort_index()\n",
    "\n",
    "# View new DataFrame with the new bin(categories) columns\n",
    "diabities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dea6b9-1d0d-4d04-86b6-e2e48b8ec399",
   "metadata": {},
   "source": [
    "***3.2. Data Binning in Numpy Array***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec68112-7432-4bb7-8a56-171a802e3b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample NumPy array of exam scores\n",
    "scores = np.array([75, 82, 95, 68, 90, 85, 78, 72, 88, 93, 60, 72, 80])\n",
    "\n",
    "# Define the bin intervals\n",
    "bin_edges = [0, 60, 70, 80, 90, 100]\n",
    "\n",
    "# Use histogram to count the number of scores in each bin\n",
    "bin_counts, _ = np.histogram(scores, bins=bin_edges)\n",
    "\n",
    "# Plot a histogram of the binned scores\n",
    "plt.bar(range(len(bin_counts)), bin_counts, align='center')\n",
    "plt.xticks(range(len(bin_edges) - 1), ['<60', '60-69', '70-79', '80-89', '90+'])\n",
    "plt.xlabel('Score Range')\n",
    "plt.ylabel('Number of Scores')\n",
    "plt.title('Distribution of Exam Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e437b756-7b2c-47c7-9502-2974cd0ae458",
   "metadata": {},
   "source": [
    "In text files, data binning can be grouping and categorizing of text data based on some criteria.To perform it simply :\n",
    "1. Determine a criteria for binning. For example: Could be count of sentences in text, word count, sentiment score, topic.\n",
    "2. Read text and calculate the choosen criteria for binning. For example: Count number of words in bins.\n",
    "3. Define bins based on range of values for the choosen criteria. For example: Defining short, medium, long based on word count of text.\n",
    "4. Assign text files appropriate bin based on calculated value.\n",
    "5. Analyse or summerize the data in the new bins\n",
    "\n",
    "Some use cases of binning in text file:\n",
    "a. Grouping text files based on their length.\n",
    "b. Binning based on the sentiment analysis score.\n",
    "c. Topic binning by performing topic modelling.\n",
    "d. Language binning if text files are in different languages.\n",
    "e. Time-based binning if text files have timestamps. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b31ca2e-acbf-42b8-94fd-de64afe7e082",
   "metadata": {},
   "source": [
    "***3.3. Data Binning in Text file collection using word count***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fd1cab-5e93-40af-a577-d45f804a1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "path = \"/workspaces/ImplementingStatisticsWithPython/data/chapter1/TransactionNarrative\"\n",
    "files = glob.glob(path + \"/*.txt\")\n",
    "\n",
    "# Function that takes a file name as an argument and returns the word count of that file\n",
    "def word_count(file):\n",
    "    # Open the file in read mode\n",
    "    with open(file, \"r\") as f:\n",
    "        # Read the file content\n",
    "        content = f.read()\n",
    "        # Split the content by whitespace characters\n",
    "        words = content.split()\n",
    "        # Return the length of the words list\n",
    "        return len(words)\n",
    "\n",
    "counts = [word_count(file) for file in files]\n",
    "\n",
    "binning_df = pd.DataFrame({\"file\": files, \"count\": counts})\n",
    "binning_df[\"bin\"] = pd.cut(binning_df[\"count\"], bins=[0, 26, 30, 35])\n",
    "binning_df[\"bin\"] = pd.cut(binning_df[\"count\"], bins=[0, 26, 30, 35], labels=[\"Short\", \"Medium\", \"Long\"])\n",
    "binning_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7680bf7c-0edd-4764-ad30-0f107f03869b",
   "metadata": {},
   "source": [
    "In unstructured data data binning can be used for text categorization and modelling of text data, color quantization and feature extraction on image data,\n",
    "audio segmentation and feature extraction on audio data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be61ddf0-1005-44ad-8641-afce78d3b9a8",
   "metadata": {},
   "source": [
    "***3.3. Grouping***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3335576-fb28-4db6-8bbe-4d4c2f502f9e",
   "metadata": {},
   "source": [
    "***3.3.1.Groping of the DataFrame based on the condition and binning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100e988-cebb-4d76-b29a-b49399694543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with student data\n",
    "data = {'Name': ['John', 'Anna', 'Peter', 'Carol', 'David', 'Oystein','Hari'],\n",
    "        'Age': [15, 16, 17, 15, 16, 14, 16],\n",
    "        'Score': [85, 92, 78, 80, 88, 77, 89]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group the data based on age intervals (e.g., 14-16, 17-18, etc.)\n",
    "age_intervals = pd.cut(df['Age'], bins=[13, 16, 18])\n",
    "grouped_data = df.groupby(age_intervals)['Score'].mean()\n",
    "\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd1f79-0062-48c5-b62f-9fa311a933c8",
   "metadata": {},
   "source": [
    "***3.3.2. Scikit-learn digit datasets can be grouped based on relevant criteria such as the target labels***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1de465e-c4f8-46ff-8e75-a2e467cd59e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Class to display and perform grouping of digits\n",
    "class Digits_Grouping:\n",
    "    # Contructor method to initialize the object's attributes\n",
    "    def __init__(self,digits):\n",
    "        self.digits = digits\n",
    "\n",
    "    def display_digit_image(self):\n",
    "        # Get the images and labels from the dataset\n",
    "        images = self.digits.images\n",
    "        labels = self.digits.target\n",
    "        \n",
    "        # Display the first few images along with their labels\n",
    "        num_images_to_display = 5  # You can change this number as needed\n",
    "\n",
    "        # Plot the selected few image in a subplot\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        for i in range(num_images_to_display):\n",
    "            plt.subplot(1, num_images_to_display, i + 1)\n",
    "            plt.imshow(images[i], cmap='gray')\n",
    "            plt.title(f\"Label: {labels[i]}\")\n",
    "            plt.axis('off')\n",
    "        # Display the plot\n",
    "        plt.show()\n",
    "\n",
    "    def display_label_based_grouping(self):\n",
    "        # Group the data based on target labels\n",
    "        grouped_data = {}\n",
    "        # Iterate through each image and its corresponding target in the dataset.\n",
    "        for image, target in zip(self.digits.images, self.digits.target):\n",
    "            # Check if the current target value is not already present as a key in grouped_data.\n",
    "            if target not in grouped_data:\n",
    "                # If the target is not in grouped_data, add it as a new key with an empty list as the value.\n",
    "                grouped_data[target] = []\n",
    "            \n",
    "            # Append the current image to the list associated with the target key in grouped_data.\n",
    "            grouped_data[target].append(image)\n",
    "\n",
    "        # Print the number of samples in each group\n",
    "        for target, images in grouped_data.items():\n",
    "            print(f\"Target {target}: {len(images)} samples\")\n",
    "\n",
    "displayDigit = Digits_Grouping(load_digits())\n",
    "displayDigit.display_digit_image()\n",
    "displayDigit.display_label_based_grouping()\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a9d358-9223-49cc-a076-41d24ad9fac9",
   "metadata": {},
   "source": [
    "***3.4. Encoding***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68089466-73aa-4a59-84c2-e97522f1a9d2",
   "metadata": {},
   "source": [
    "***3.4.1. One-hot encoding tutorial with method get_dummies()***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f170c3b-8516-4821-8949-8b02a2b67526",
   "metadata": {},
   "source": [
    "One-hot encoding creates a new column for each distinct value of the category variable, and the presence or absence of that value in each row is denoted by a binary value of 1 or 0. It encodes categorical data in a way that machine learning algorithms can understand and interpret. However, it makes the data more dimensional and produces sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea709b0b-d9ec-4afc-b5b8-18a6cf36d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataframe with 3 columns: name, gender and color\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Ane', 'Bo', 'Lee', 'Dam', 'Eva'],\n",
    "    'gender': ['F', 'M', 'M', 'M', 'F', 'F', 'M', 'M', 'M', 'F'],\n",
    "    'color': ['red', 'blue', 'green', 'yellow', 'pink', 'red', 'blue', 'green', 'yellow', 'pink']\n",
    "})\n",
    "\n",
    "# Print the original dataframe\n",
    "print(df)\n",
    "\n",
    "# Apply one hot encoding on the gender and color columns using pandas.get_dummies()\n",
    "df_encoded = pd.get_dummies(df, columns=['gender', 'color'], dtype=int)\n",
    "\n",
    "# Print the encoded dataframe\n",
    "df_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07363d67-c07e-40ef-839e-88fb2fd68de3",
   "metadata": {},
   "source": [
    "***3.4.2. One-hot encoding on the complete dataframe with object column***\n",
    "<br>\n",
    "Dataset used:  \n",
    "Becker,Barry and Kohavi,Ronny. (1996). Adult. UCI Machine Learning Repository. https://doi.org/10.24432/C5XW20.\n",
    "Accessed From: https://archive.ics.uci.edu/dataset/2/adult \n",
    "Used under the Creative Commons Attribution 0.0 International license (CC0: Public Domain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf45953-5959-47bc-b4a0-e5a6b1430afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Read the json file from the direcotory\n",
    "diabities_df = pd.read_csv(\"/workspaces/ImplementingStatisticsWithPython/data/chapter2/Adult_UCI/adult.data\")\n",
    "\n",
    "def one_hot_encoding(diabities_df):\n",
    "    # Identify columns that are categorical to apply one hot encoding in them only\n",
    "    columns_for_one_hot = diabities_df.select_dtypes(include=\"object\").columns\n",
    "    \n",
    "    # Apply one hot encoding to the categorical columns\n",
    "    diabities_df = pd.get_dummies(diabities_df, columns=columns_for_one_hot, prefix=columns_for_one_hot, dtype=int)\n",
    "    \n",
    "    # Display the transformed dataframe\n",
    "    print(display(diabities_df.head(5)))\n",
    "\n",
    "one_hot_encoding(diabities_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46d60cb-bbe6-467c-bf12-065ffd614a39",
   "metadata": {},
   "source": [
    "***3.4.3. Binary encoding tutorial***\n",
    "<br>\n",
    "For this lets use `category_encoders` using `pip install category_encoders`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f00f59-ce80-4d05-8331-d0eeda165c55",
   "metadata": {},
   "source": [
    "Binary coding first assigns an integer value to each distinct category in the categorical variable and then converts that integer value into a binary code. Unlike hot coding, which adds a new column for each distinct category, binary coding minimizes the number of columns needed to describe categorical data. However, binary coding has drawbacks, including adding ordinality or hierarchy to categories that may not already exist and making interpretation and analysis more difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f3494e-97f7-40a6-b4aa-a2e9456b550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas library and category_encoders library\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# Create a sample dataframe with 3 columns: name, gender and color\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Ane', 'Bo', 'Lee', 'Dam', 'Eva'],\n",
    "    'gender': ['F', 'M', 'M', 'M', 'F', 'F', 'M', 'M', 'M', 'F'],\n",
    "    'color': ['red', 'blue', 'green', 'yellow', 'pink', 'red', 'blue', 'green', 'yellow', 'pink']\n",
    "})\n",
    "\n",
    "# Print the original dataframe\n",
    "print(df)\n",
    "\n",
    "# Create a binary encoder object\n",
    "encoder = ce.BinaryEncoder(cols=['name', 'gender', 'color'])\n",
    "\n",
    "# Fit and transform the dataframe using the encoder\n",
    "df_encoded = encoder.fit_transform(df)\n",
    "\n",
    "# Print the encoded dataframe\n",
    "print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894a564e-c04a-4468-a02e-4a4918027b70",
   "metadata": {},
   "source": [
    "***Difference betweeen binary encoder and label encoder is:***\n",
    "<br> One-hot encoding: A hot encoding creates a new column for each possible value of the categorical variable and assigns a 1 or 0 to indicate whether that value exists or not. \n",
    "For example, the gender column in the data frame can be hot coded as follows.\n",
    "\n",
    "Binary encoding converts each possible value of the categorical variable into a binary code, and then divides the code into separate columns. \n",
    "For example, the gender column and the Color column in the data frame can be hot coded as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df075f0-ea42-4a57-8fea-61fb49804f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "class Encoders_Difference:\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "\n",
    "    def one_hot_encoding(self):\n",
    "        df_encoded1 = pd.get_dummies(df, columns=['color'],dtype=int)\n",
    "        display(df_encoded1)\n",
    "\n",
    "    def binary_encoder(self):\n",
    "        encoder = ce.BinaryEncoder(cols=['color'])\n",
    "        df_encoded2 = encoder.fit_transform(df)\n",
    "        display(df_encoded2)\n",
    "        \n",
    "\n",
    "# Create a sample dataframe with 3 columns: name, gender and color\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Ane', 'Bo', 'Lee', 'Dam', 'Eva'],\n",
    "    'gender': ['F', 'M', 'M', 'M', 'F', 'F', 'M', 'M', 'M', 'F'],\n",
    "    'color': ['red', 'blue', 'green', 'yellow', 'pink', 'red', 'blue', 'green', 'yellow', 'pink']\n",
    "})\n",
    "\n",
    "encoderDifference_obj = Encoders_Difference(df)\n",
    "encoderDifference_obj.one_hot_encoding()\n",
    "encoderDifference_obj.binary_encoder()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b605fe-190c-489e-adbf-a41523ed7a3e",
   "metadata": {},
   "source": [
    "***3.4.3. Label encoding tutorial***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3232e58a-a11e-47b5-94ae-ea3a11fd6c29",
   "metadata": {},
   "source": [
    "Label encoder works by assigning an integer value to each unique category in the categorical variable, starting from 0. The transformed variable will have numerical values instead of categorical values. Its drawback is the loss of information about the similarity or difference between categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f39b73-2cf3-423e-918b-9ed1e3d9d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Ane', 'Bo', 'Lee', 'Dam', 'Eva'],\n",
    "    'gender': ['F', 'M', 'M', 'M', 'F', 'F', 'M', 'M', 'M', 'F'],\n",
    "    'color': ['red', 'blue', 'green', 'yellow', 'pink', 'red', 'blue', 'green', \n",
    "'yellow', \n",
    "'pink']\n",
    "})\n",
    "\n",
    "# cat.codes is a method that returns the category codes of a categorical variable\n",
    "df['gender_label'] = df['gender'].astype('category').cat.codes\n",
    "df['color_label'] = df['color'].astype('category').cat.codes\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa44d19-dbd8-4a3d-a260-0518f2df8f86",
   "metadata": {},
   "source": [
    "**Tutorial 4. Missing Data, Detecting and Treating Outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e8d4b-e5ae-4883-b90d-615b99ab3cbf",
   "metadata": {},
   "source": [
    "**Missing Data and how to handle missing data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0f7d74-6c35-42d4-980f-16b4c3e930ba",
   "metadata": {},
   "source": [
    "Data values that are not stored or captured for some variables or observations in a dataset are referred to as missing data. It may happen for a number of reasons, including human mistakes, equipment malfunctions, data entry challenges, privacy concerns, or flaws with survey design. The accuracy and reliability of the analysis and inference can be impacted by missing data. \n",
    "In structured data identifying missing values is pretty easy whereas in semi and unstructured it may not always be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e96d48-0162-407b-980f-38af165082f7",
   "metadata": {},
   "source": [
    "Ways to handle missing data\n",
    "<br>\n",
    "1. Deletion\n",
    "2. Imputation\n",
    "3. Prediction of missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee68d33-6d69-4cbd-a2a6-079d1d4c18ec",
   "metadata": {},
   "source": [
    "**4.1. Deletion or drop a column from a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec08da8-00c4-4501-be59-7e4a7912e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Read the json file from the direcotory\n",
    "diabities_df = pd.read_csv(\"/workspaces/ImplementingStatisticsWithPython/data/chapter2/Adult_UCI/adult.data\")\n",
    "\n",
    "# Drop the 'Age' and 'Work' columns\n",
    "diabities_df = diabities_df.drop(columns=[' Work', ' person_id', ' education', ' education_number',\n",
    "       ' marital_status'], axis=1)\n",
    "\n",
    "# Verify the updated DataFrame\n",
    "diabities_df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15507a6c-47ae-4db4-8d98-c78a8d16d8e6",
   "metadata": {},
   "source": [
    "**4.2. Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0737986b-7911-424b-95dc-0de7e23c51aa",
   "metadata": {},
   "source": [
    "Basic inputation can be done with `mean()`, `median()`, `mode()` , random constant value , or in some cases prediction can be done and predicted value can be imputed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f658ac2-e230-437a-ad4b-a339d68f5dd4",
   "metadata": {},
   "source": [
    "4.2.1 Imputation of mean value with `mean()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6cd00b-0425-42d3-8114-900a02e6d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Create a DataFrame with student data\n",
    "data = {'Name': ['John', 'Anna', 'Peter', 'Carol', 'David', 'Oystein','Hari', 'Suresh','Ram'],\n",
    "        'Age': [15, 16, np.nan, 15, 16, 14, 16, 30, 31],\n",
    "        'Score': [85, 92, 78, 80, np.nan, 77, 89, 99, 76]}\n",
    "student_DF = pd.DataFrame(data)\n",
    "print(f'Before Mean Inputation DataFrame')\n",
    "display(student_DF)\n",
    "\n",
    "mean_age = student_DF['Age'].mean()\n",
    "mean_score = student_DF['Score'].mean()\n",
    "print(f'DataFrame after mean imputation')\n",
    "student_DF = student_DF.fillna(value= {'Age' : mean_age, 'Score': mean_score})\n",
    "display(student_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8733e51-8bcd-43fe-a958-e9448720438e",
   "metadata": {},
   "source": [
    "4.2.2. Imputation by median value. Here we do with `median()` also `SimpleImputer()` from the sklearn `from sklearn.impute import SimpleImputer` can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff50fb8-66f4-47c2-bff4-6126c842ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Create a DataFrame with student data\n",
    "data = {'Name': ['John', 'Anna', 'Peter', 'Carol', 'David', 'Oystein','Hari', 'Suresh','Ram'],\n",
    "        'Age': [15, 16, np.nan, 15, 16, 14, 16, 30, 31],\n",
    "        'Score': [85, 92, 78, 80, np.nan, 77, 89, 99, 76]}\n",
    "student_DF = pd.DataFrame(data)\n",
    "print(f'Before Median Inputation DataFrame')\n",
    "display(student_DF)\n",
    "\n",
    "median_age = student_DF['Age'].median()\n",
    "median_score = student_DF['Score'].median()\n",
    "print(f'DataFrame After Median Imputation')\n",
    "student_DF = student_DF.fillna(value= {'Age' : median_age, 'Score': median_score})\n",
    "display(student_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee49916-1c15-44fe-a09a-9c88fb685943",
   "metadata": {},
   "source": [
    "**4.3. Prediction of missing value**\n",
    "Missing values can be estimated and predicted based on other available information in the dataset. If estimates are not done properly it can introduce noise and uncertainty in the data. The missing values (missingness) can also be used as a variable, indicating whether a value was missing or not, if appropriate. But doing so can increase dimensionality. More on this will be discussed in Chapter 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206bfa96-6a79-4af2-bde3-269c9342353f",
   "metadata": {},
   "source": [
    "Some general guilines:\n",
    "1. If the missing data is randomly distributed across the dataset and not too many (less than 5% of the total observations), then a simple method such as replacing the missing values with the mean, median, or mode of the corresponding variable may be sufficient. This method is implemented by the SimpleImputer class in scikit-learn.\n",
    "2. If the missing data are not randomly distributed or are too many (more than 5% of the total observations), a simple method may introduce bias and reduce the variability of the data. In this case, a more sophisticated method that takes into account the relationship between variables may be preferable. For example, you can use a regression model to predict the missing values based on other variables, or a nearest neighbor approach to find the most similar observation and use its value as an imputation.\n",
    "3. If the missing data are longitudinal, that is, they occur in repeated measurements over time, then a method that accounts for the temporal structure of the data may be more appropriate. For example, one can use a time series model to predict the missing values based on past and future observations, or a mixed effects model to account for both fixed and random effects over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0c534e-2bf8-4567-8594-a819281cd012",
   "metadata": {},
   "source": [
    "**Tutorial 5. Histograms, Box plots, Scatter plots, Pie Charts, Bar Charts, X-Y Plots, Heatmaps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae7612-d052-47b5-879c-707ca6cc366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "While plotting information in the plot the first thing to do is, to identify which kind of plot is appropriate for that data.\n",
    "To know which plot is useful for what kind of data, you can check out this website: \n",
    "1. https://www.data-to-viz.com/\n",
    "2. https://datavizproject.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca160d-4cbe-4822-82fc-e9d333835ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.1. Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce8dc0c-9adf-4e76-a8e7-43064961da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create your data\n",
    "data = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5]\n",
    "\n",
    "# Create the histogram\n",
    "plt.hist(data)\n",
    "\n",
    "# Customize the plot (add labels, title, etc.)\n",
    "plt.xlabel('X-axis Label')\n",
    "plt.ylabel('Y-axis Label')\n",
    "plt.title('Histogram Title')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebed68d-2b6c-4b5a-9a57-d504313716dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.2. Pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda40d30-3c8c-46ab-b98c-ccdf5cd3aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sizes = [15, 30, 45, 10]  \n",
    "labels = ['Category A', 'Category B', 'Category C', 'Category D']  \n",
    "colors = ['blue', 'green', 'red', 'purple']  \n",
    "\n",
    "# Create the pie chart\n",
    "plt.pie(sizes, labels=labels)\n",
    "\n",
    "# Customize the plot (add title, aspect ratio, etc.)\n",
    "plt.axis('equal')  \n",
    "plt.title('Pie Chart Title')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae46a426-cdf2-4113-8968-43b44e2d5d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.3. Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc7822-c748-47d9-9083-e913674cc421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create your data\n",
    "categories = ['Category A', 'Category B', 'Category C', 'Category D']\n",
    "values = [10, 25, 15, 30]\n",
    "\n",
    "# Create the bar chart\n",
    "plt.bar(categories, values)\n",
    "\n",
    "# Customize the plot (add labels, title, etc.)\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Bar Chart Title')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7e6435-0367-474c-ab41-630dca98e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.4. Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f7c42-8b2f-43a0-91ec-61d843de7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create your data\n",
    "x_data = [1, 2, 3, 4, 5]\n",
    "y_data = [10, 15, 13, 20, 18]\n",
    "\n",
    "# Create the line plot\n",
    "plt.plot(x_data, y_data)\n",
    "\n",
    "# Customize the plot (add labels, title, etc.)\n",
    "plt.xlabel('X-axis Label')\n",
    "plt.ylabel('Y-axis Label')\n",
    "plt.title('Line Plot Title')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9bc012-6fc7-4340-9482-b9389bd2836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.5. Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c9fe6-428b-42f4-8fc4-122a493d1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample DataFrame (replace this with your own DataFrame)\n",
    "data = {'X': [1, 2, 3, 4, 5],\n",
    "        'Y': [10, 15, 13, 20, 18]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract the columns you want to plot\n",
    "x_data = df['X']\n",
    "y_data = df['Y']\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.scatter(x_data, y_data, marker='o')\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Scatter Plot Example')\n",
    "\n",
    "# Show a legend if needed\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
